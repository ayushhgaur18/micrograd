# micrograd
"A compact automatic differentiation engine powers this tool, enabling the implementation of backpropagation (using reverse-mode automatic differentiation).
It features a concise neural network library crafted atop this foundation with an API reminiscent of PyTorch.
Functions solely through scalar operations, such as individual additions and multiplications of each neuron.